{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "conditional-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import requests\n",
    "import shutil\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "developing-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSafeDir(fp):\n",
    "    if not os.path.exists(fp):\n",
    "        os.makedirs(fp)\n",
    "        \n",
    "def preProcessCaption(caption):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    return tokenizer.tokenize(caption.lower())\n",
    "\n",
    "\n",
    "# code from https://stackoverflow.com/questions/18470627/how-do-i-remove-the-microseconds-from-a-timedelta-object\n",
    "def cm(delta):\n",
    "    return delta - datetime.timedelta(microseconds=delta.microseconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beneficial-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset_dir = \"custom_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "anonymous-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordseye_number = 120000 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "absent-jason",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************************************************************\n",
      "starting\n",
      "ending - stats -- total_count: 70, failed_count: 0, success_count: 70, time_elapsed: 0:00:00\n",
      "***********************************************************************************************\n",
      "\n",
      "\n",
      "len(datapoint_dict_list): 70\n"
     ]
    }
   ],
   "source": [
    "createSafeDir(\"created_data\")\n",
    "createSafeDir(\"created_data/train\")\n",
    "\n",
    "datapoint_dict_list = []\n",
    "global_idx = 0\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "print(\"***********************************************************************************************\", flush = True)\n",
    "print(\"starting\", flush = True)\n",
    "total_count = 0\n",
    "failed_count = 0\n",
    "\n",
    "count = 0\n",
    "for datapoint in os.listdir(custom_dataset_dir):\n",
    "    total_count = total_count + 1\n",
    "    datapoint_id = wordseye_number\n",
    "    datapoint_caption = \"\".join(re.split(\"[^a-zA-Z]*\", datapoint.split('.')[0]))\n",
    "    \n",
    "    wordseye_filename = \"ws-image-db_2021-4-15_\" + str(wordseye_number) + \".jpg\"\n",
    "    datapoint_dict = {\n",
    "                            \"filepath\": \"train\",\n",
    "                            \"sentids\": [global_idx],\n",
    "                            \"filename\": wordseye_filename,\n",
    "                            \"imgid\": global_idx,\n",
    "                            \"split\": \"train\",\n",
    "                            \"sentences\": [{\n",
    "                                \"tokens\": preProcessCaption(datapoint_caption),\n",
    "                                \"raw\": datapoint_caption,\n",
    "                                \"imgid\": global_idx,\n",
    "                                \"sentid\": global_idx\n",
    "                            }],\n",
    "                            'wordseyeid': global_idx\n",
    "\n",
    "    }\n",
    "    \n",
    "    shutil.copy(custom_dataset_dir + \"/\" + datapoint, \"created_data/train/\" + wordseye_filename)\n",
    "    datapoint_dict_list.append(datapoint_dict)\n",
    "    global_idx = global_idx + 1\n",
    "    wordseye_number = wordseye_number + 1\n",
    "\n",
    "\n",
    "print(\"ending - stats -- total_count: {}, failed_count: {}, success_count: {}, time_elapsed: {}\".format(total_count, failed_count, total_count - failed_count, cm(datetime.datetime.now() - start_time)), flush = True)\n",
    "print(\"***********************************************************************************************\", flush = True)\n",
    "print(\"\", flush = True)\n",
    "print(\"\", flush = True)\n",
    "\n",
    "\n",
    "print(\"len(datapoint_dict_list): {}\".format(len(datapoint_dict_list)))\n",
    "content = {\n",
    "    \"dataset\": \"wordseye\",\n",
    "    \"images\": datapoint_dict_list\n",
    "}\n",
    "\n",
    "f2 = open(\"created_data/dataset_custom_wordseye.json\", \"w\")\n",
    "json.dump(content, f2, indent = 4)\n",
    "f2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "vanilla-operations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120071\n"
     ]
    }
   ],
   "source": [
    "print(wordseye_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-moldova",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
